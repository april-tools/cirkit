{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f3b03e-0aa7-4fa9-ad37-21a141f4a1a1",
   "metadata": {},
   "source": [
    "# Train and evaluate a squared PC ($\\mathrm{NPC}^2$) with real parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498b64a5-86bf-45c7-b65c-6c010a9b4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e26e8e-8c76-43ce-90db-87da5d8eb39a",
   "metadata": {},
   "source": [
    "Set the random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63dd05c5-f4ea-459a-b2fb-75d976f50afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d389743-936c-49a8-9ef8-f5c55be758a5",
   "metadata": {},
   "source": [
    "# Load the MiniBooNE UCI data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b76039-c260-4b43-88e2-e3e8875206bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_uci_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b153dc84-3e0b-463a-99b0-2b7e09a388af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables: 43\n"
     ]
    }
   ],
   "source": [
    "data = load_uci_dataset('miniboone', path='datasets')\n",
    "data_train, data_test = data['train'], data['test']\n",
    "num_variables = data_train.shape[1]\n",
    "print(f'Number of variables: {num_variables}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611257b5-8c18-4f1d-8316-3c898f2e6035",
   "metadata": {},
   "source": [
    "# Instantiating a Circuit structure Template: the Region Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ef46af-2e7d-46cf-ad72-52db50d5f939",
   "metadata": {},
   "source": [
    "Instantiate a bunch of _random binary tree_ region graphs of maximum depth, with different seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4559103-4e61-4b6c-ac72-ff54c72e0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.templates.region_graph import RandomBinaryTree\n",
    "max_depth = int(np.ceil(np.log2(num_variables)))\n",
    "region_graph = RandomBinaryTree(num_variables, depth=max_depth, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c77dea-c04a-4349-80e3-d78c508339c9",
   "metadata": {},
   "source": [
    "## Constructing the Symbolic Circuit Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db495e-1065-43fa-97f4-b3b1ad1f0b32",
   "metadata": {},
   "source": [
    "We construct a non-monotonic PC with Gaussian distributions as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84505053-eab3-491f-b143-89eda6f86224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.utils.scope import Scope\n",
    "from cirkit.symbolic.layers import GaussianLayer, DenseLayer, HadamardLayer\n",
    "from cirkit.symbolic.parameters import Parameter, TensorParameter, ScaledSigmoidParameter\n",
    "from cirkit.symbolic.initializers import UniformInitializer, NormalInitializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a27d1ce-3fc7-4ea0-8e4c-2b1f2cd5b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_layer_factory(\n",
    "    scope: Scope,\n",
    "    num_units: int,\n",
    "    num_channels: int\n",
    ") -> GaussianLayer:\n",
    "    return GaussianLayer(\n",
    "        scope, num_units, num_channels,\n",
    "        stddev_factory=lambda shape: Parameter.from_sequence(\n",
    "            TensorParameter(*shape, initializer=NormalInitializer(0.0, 1e-1)),\n",
    "            ScaledSigmoidParameter(shape, vmin=1e-5, vmax=1.0)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def hadamard_layer_factory(\n",
    "    scope: Scope, num_input_units: int, arity: int\n",
    ") -> HadamardLayer:\n",
    "    return HadamardLayer(scope, num_input_units, arity)\n",
    "\n",
    "def dense_layer_factory(\n",
    "    scope: Scope,\n",
    "    num_input_units: int,\n",
    "    num_output_units: int\n",
    ") -> DenseLayer:\n",
    "    return DenseLayer(\n",
    "        scope, num_input_units, num_output_units,\n",
    "        weight_factory=lambda shape: Parameter.from_leaf(\n",
    "            TensorParameter(*shape, initializer=UniformInitializer(0.0, 1.0)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f5c34a5-f6c1-4735-ba88-76ab00ef35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.symbolic.circuit import Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ecd1c60-402f-4e65-b79a-8ddbd69dd700",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_circuit = Circuit.from_region_graph(\n",
    "    region_graph,\n",
    "    num_input_units=64,\n",
    "    num_sum_units=64,\n",
    "    input_factory=gaussian_layer_factory,\n",
    "    sum_factory=dense_layer_factory,\n",
    "    prod_factory=hadamard_layer_factory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad50a2-b91b-4934-bf36-061442375583",
   "metadata": {},
   "source": [
    "We can retrieve some information about the circuit and its structural properties as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de247e7e-d5bf-44e8-adc8-f070a86ad236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smooth: True\n",
      "Decomposable: True\n",
      "Structured decomposable: True\n",
      "Number of variables: 43\n",
      "Number of channels per variable: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Smooth: {symbolic_circuit.is_smooth}')\n",
    "print(f'Decomposable: {symbolic_circuit.is_decomposable}')\n",
    "print(f'Structured decomposable: {symbolic_circuit.is_structured_decomposable}')\n",
    "print(f'Number of variables: {symbolic_circuit.num_variables}')\n",
    "print(f'Number of channels per variable: {symbolic_circuit.num_channels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eff399-2f7c-4836-9b65-78622f4be7d6",
   "metadata": {},
   "source": [
    "## Computing the Circuit Square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a841699-70ec-44f3-b90b-24d92722eabd",
   "metadata": {},
   "source": [
    "We now square the symbolic circuit representation and compile it. However, to actually train it, we will only need to compute the integral of the squared circuit.\n",
    "\n",
    "To do so, we need to set up a pipeline context first and specify a backend. Since the circuit is non-monotonic, we will use the complex log-sum-exp and sum semiring. Note that in the following we also compile the integral of the squared circuit, i.e., the partition functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a01f3c5-21d1-4677-af7d-bd6bc5d8f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.pipeline import PipelineContext\n",
    "from cirkit.pipeline import compile\n",
    "import cirkit.symbolic.functional as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a89681ce-efcf-4dae-acf3-9448502f21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')  # The device to use\n",
    "torch.manual_seed(42)\n",
    "# Using float32 ...\n",
    "#torch.set_default_dtype(torch.float64)\n",
    "torch.cuda.manual_seed(42)\n",
    "# Extend the default cache limit. In the future, torch will support compilation with 'more dynamic shapes',\n",
    "# and therefore many recompilations will be avoided\n",
    "torch._dynamo.config.cache_size_limit = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78bd1d2b-018f-47fa-a2df-e3ddfc816ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 315 ms, sys: 28.7 ms, total: 343 ms\n",
      "Wall time: 345 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ctx = PipelineContext(\n",
    "    backend='torch',   # Choose the torch compilation backend\n",
    "    fold=True,         # Fold the circuit, this is a backend-specific compilation flag\n",
    "    semiring='complex-lse-sum', # Use the (C, +, *) semiring, where + is the complex log-sum-exp and * is the sum\n",
    "    optimize=True      # Optimize the circuit layers (set this flag to False to disable, which yields slower inference)\n",
    ")\n",
    "\n",
    "with ctx:\n",
    "    symbolic_sq_circuit = SF.multiply(symbolic_circuit, symbolic_circuit)\n",
    "    symbolic_int_sq_circuit = SF.integrate(symbolic_sq_circuit)\n",
    "    int_sq_circuit = compile(symbolic_int_sq_circuit)\n",
    "    # Note that compiling the integral squared circuit will also compile the symbolic circuit\n",
    "    # we started from. We retrieve its compiled module as showed below.\n",
    "    circuit = ctx.get_compiled_circuit(symbolic_circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acead97f-2783-45ba-b2b1-0ef164fd2481",
   "metadata": {},
   "source": [
    "Let's print the circuit and the integral squared circuit torch modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bf4de33-c03f-4a69-9103-6a6b4a5ffec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchCircuit(\n",
      "  (_nodes): ModuleList(\n",
      "    (0): TorchGaussianLayer(\n",
      "      (mean): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "        )\n",
      "      )\n",
      "      (stddev): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchScaledSigmoidParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2-7): 6 x TorchCPLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc5922e-c1d8-41b7-856a-759ee9aa253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchConstantCircuit(\n",
      "  (_nodes): ModuleList(\n",
      "    (0): TorchLogPartitionLayer(\n",
      "      (value): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0-1): 2 x TorchPointerParameter(\n",
      "            (_parameter): TorchTensorParameter()\n",
      "          )\n",
      "          (2): TorchScaledSigmoidParameter()\n",
      "          (3): TorchGaussianProductLogPartition()\n",
      "          (4-5): 2 x TorchReduceSumParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1-2): 2 x TorchTensorDotLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchPointerParameter(\n",
      "            (_parameter): TorchTensorParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): TorchHadamardLayer()\n",
      "    (4-5): 2 x TorchTensorDotLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchPointerParameter(\n",
      "            (_parameter): TorchTensorParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): TorchHadamardLayer()\n",
      "    (7-8): 2 x TorchTensorDotLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchPointerParameter(\n",
      "            (_parameter): TorchTensorParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): TorchHadamardLayer()\n",
      "    (10-11): 2 x TorchTensorDotLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchPointerParameter(\n",
      "            (_parameter): TorchTensorParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): TorchHadamardLayer()\n",
      "    (13-14): 2 x TorchTensorDotLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchPointerParameter(\n",
      "            (_parameter): TorchTensorParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): TorchHadamardLayer()\n",
      "    (16-17): 2 x TorchTensorDotLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchPointerParameter(\n",
      "            (_parameter): TorchTensorParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): TorchHadamardLayer()\n",
      "    (19-20): 2 x TorchTensorDotLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchPointerParameter(\n",
      "            (_parameter): TorchTensorParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(int_sq_circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6510a-0631-4770-9002-9431f126bb9d",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c644c-ac45-4156-b1f5-391585ea34c7",
   "metadata": {},
   "source": [
    "We are not ready to learn the parameters and do inference.\n",
    "First, we wrap our data into PyTorch data loaders by specifying the batch size.\n",
    "Then, we initialize any PyTorch optimizer, e.g., Adam.\n",
    "\n",
    "Note that the parameters of the integral squared circuit are the same parameters of the circuit itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a0f61c6-7564-4c3b-8612-e02a52160d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea7b248b-802e-4f22-9849-2b5fe304b019",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(data_train, shuffle=True, batch_size=256, drop_last=True, num_workers=4)\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=256, num_workers=4)\n",
    "optimizer = optim.Adam(circuit.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee8840b0-617c-4881-8753-313b1491f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move circuits to device\n",
    "circuit = circuit.to(device)\n",
    "int_sq_circuit = int_sq_circuit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13f65113-023f-4e9f-922a-e7202de5bb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, step 500: Average NLL: 63.504\n",
      "Epoch 8, step 1000: Average NLL: 55.648\n",
      "Epoch 13, step 1500: Average NLL: 52.484\n",
      "Epoch 17, step 2000: Average NLL: 50.936\n",
      "Epoch 21, step 2500: Average NLL: 49.458\n",
      "Epoch 26, step 3000: Average NLL: 48.287\n",
      "Epoch 30, step 3500: Average NLL: 49.778\n",
      "Epoch 35, step 4000: Average NLL: 49.997\n",
      "Epoch 39, step 4500: Average NLL: 48.489\n",
      "Epoch 43, step 5000: Average NLL: 48.381\n",
      "Epoch 48, step 5500: Average NLL: 48.535\n",
      "Epoch 52, step 6000: Average NLL: 47.784\n",
      "Epoch 57, step 6500: Average NLL: 47.131\n",
      "Epoch 61, step 7000: Average NLL: 47.028\n",
      "Epoch 65, step 7500: Average NLL: 46.472\n",
      "Epoch 70, step 8000: Average NLL: 46.241\n",
      "Epoch 74, step 8500: Average NLL: 46.224\n",
      "Epoch 78, step 9000: Average NLL: 45.836\n",
      "Epoch 83, step 9500: Average NLL: 46.752\n",
      "Epoch 87, step 10000: Average NLL: 46.923\n",
      "Epoch 92, step 10500: Average NLL: 46.105\n",
      "Epoch 96, step 11000: Average NLL: 45.679\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "step_idx = 0\n",
    "running_loss = 0.0\n",
    "for epoch_idx in range(num_epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        batch = batch.to(device).unsqueeze(dim=1)   # Add a channel dimension\n",
    "        log_output = circuit(batch)                 # Compute the log output of the circuit\n",
    "        log_output = 2.0 * log_output.real          # Multipliying by two squares the output\n",
    "        log_pf = int_sq_circuit().real              # Compute the log partition function of the circuit\n",
    "        lls = log_output - log_pf                   # Compute the log-likelihood\n",
    "        loss = -torch.mean(lls)   # The loss is the negative average log-likelihood\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.detach() * len(batch)\n",
    "        step_idx += 1\n",
    "        if step_idx % 500 == 0:\n",
    "            print(f\"Epoch {epoch_idx}, step {step_idx}: Average NLL: {running_loss / (500 * len(batch)):.3f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b712e5df-4ad2-4ae1-a7e3-f0c1df7db254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test LL: -45.314\n"
     ]
    }
   ],
   "source": [
    "circuit.eval()\n",
    "int_sq_circuit.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_lls = 0.0\n",
    "    log_pf = int_sq_circuit().real  # Compute the log partition function of the circuit (just once as we are evaluating)\n",
    "    for batch in test_dataloader:\n",
    "        batch = batch.to(device).unsqueeze(dim=1)   # Add a channel dimension\n",
    "        log_output = circuit(batch)                 # Compute the log output of the circuit\n",
    "        log_output = 2.0 * log_output.real          # Multipliying by two squares the output\n",
    "        lls = log_output - log_pf                   # Compute the log-likelihood\n",
    "        test_lls += lls.sum().item()\n",
    "    average_ll = test_lls / len(data_test)\n",
    "    print(f\"Average test LL: {average_ll:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db6015a-b911-4f36-a471-c8ace9b9abdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
