{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f3b03e-0aa7-4fa9-ad37-21a141f4a1a1",
   "metadata": {},
   "source": [
    "# Train and Evaluate a Sum-of-Squares non-monotonic PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498b64a5-86bf-45c7-b65c-6c010a9b4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e26e8e-8c76-43ce-90db-87da5d8eb39a",
   "metadata": {},
   "source": [
    "Set the random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63dd05c5-f4ea-459a-b2fb-75d976f50afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d389743-936c-49a8-9ef8-f5c55be758a5",
   "metadata": {},
   "source": [
    "# Load the MiniBooNE UCI data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b76039-c260-4b43-88e2-e3e8875206bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_uci_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b153dc84-3e0b-463a-99b0-2b7e09a388af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables: 43\n"
     ]
    }
   ],
   "source": [
    "data = load_uci_dataset('miniboone', path='datasets')\n",
    "data_train, data_test = data['train'], data['valid']\n",
    "num_variables = data_train.shape[1]\n",
    "print(f'Number of variables: {num_variables}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611257b5-8c18-4f1d-8316-3c898f2e6035",
   "metadata": {},
   "source": [
    "# Create the Sum-of-Squares PC class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47d881c2-76a8-414e-b793-ec1579a4c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c130bf8-f85f-49ae-b76a-137af08b5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "device = torch.device('cuda')  # The device to use\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "if 'cuda' in device.type:\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56710714-ada3-4ace-b816-02788afe7a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.templates.region_graph import RegionGraph, RandomBinaryTree\n",
    "from cirkit.pipeline import PipelineContext\n",
    "from cirkit.symbolic.circuit import Circuit\n",
    "from cirkit.utils.scope import Scope\n",
    "from cirkit.symbolic.layers import GaussianLayer, DenseLayer, HadamardLayer, MixingLayer\n",
    "from cirkit.symbolic.parameters import Parameter, SoftmaxParameter, ExpParameter, ClampParameter\n",
    "from cirkit.symbolic.initializers import UniformInitializer, NormalInitializer\n",
    "import cirkit.symbolic.functional as SF\n",
    "from cirkit.backend.torch.models import TorchCircuit\n",
    "from cirkit.backend.torch.layers.inner import TorchMixingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ed44de1-052a-491b-98d7-2c638d7e090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOS(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_variables: int,\n",
    "        *,\n",
    "        num_input_units: int,\n",
    "        num_sum_units: int,\n",
    "        num_squares: int = 2,\n",
    "        seed: int = 42\n",
    "    ) -> None:\n",
    "        assert num_variables > 1\n",
    "        assert num_squares > 1\n",
    "        super().__init__()\n",
    "        max_depth = int(np.ceil(np.log2(num_variables)))\n",
    "        self._rgs = [\n",
    "            SOS._build_region_graph(num_variables, max_depth, seed=seed + i * 123)\n",
    "            for i in range(num_squares)\n",
    "        ]\n",
    "        self._ctx = PipelineContext(backend='torch', fold=True, semiring='complex-lse-sum')\n",
    "        circuit, int_sq_circuit = self.build_circuits(\n",
    "            num_input_units=num_input_units, num_sum_units=num_sum_units\n",
    "        )\n",
    "        self._circuit = circuit\n",
    "        self._int_sq_circuit = int_sq_circuit\n",
    "        self.register_buffer('_mixing_log_weight', -torch.log(torch.tensor(num_squares)))\n",
    "        self.__cache_log_z: Optional[Tensor] = None\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        if mode:\n",
    "            self.__cache_log_z = None\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                self.__cache_log_z = self._int_sq_circuit().real\n",
    "        super().train(mode)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return torch.logsumexp(self._mixing_log_weight + 2.0 * self._circuit(x).real, dim=1)\n",
    "\n",
    "    def log_likelihood(self, x: Tensor) -> Tensor:\n",
    "        if self.__cache_log_z is None:\n",
    "            log_z = self._int_sq_circuit().real\n",
    "        else:\n",
    "            log_z = self.__cache_log_z\n",
    "        log_z = torch.logsumexp(self._mixing_log_weight + log_z, dim=0)\n",
    "        log_score = self.forward(x)\n",
    "        return log_score - log_z\n",
    "\n",
    "    def build_circuits(\n",
    "        self, num_input_units: int, num_sum_units: int,\n",
    "    ) -> Tuple[TorchCircuit, TorchCircuit, TorchMixingLayer]:\n",
    "        # Build one symbolic circuit for each region graph\n",
    "        symbolic_circuits = [\n",
    "            SOS._build_symbolic_circuit(rg, num_input_units=num_input_units, num_sum_units=num_sum_units)\n",
    "            for rg in self._rgs\n",
    "        ]\n",
    "\n",
    "        # Merge the symbolic circuits into a single one having multiple outputs\n",
    "        symbolic_circuit = SF.merge(symbolic_circuits)\n",
    "\n",
    "        # Square each symbolic circuit and merge them into a single one having multiple outputs\n",
    "        symbolic_sq_circuit = SF.merge([\n",
    "            SF.multiply(sc, sc) for sc in symbolic_circuits\n",
    "        ])\n",
    "\n",
    "        # Integrate the squared circuits (by integrating the merged symbolic representation)\n",
    "        symbolic_int_sq_circuit = SF.integrate(symbolic_sq_circuit)\n",
    "\n",
    "        # Compile the symbolic circuits\n",
    "        circuit = self._ctx.compile(symbolic_circuit)\n",
    "        int_sq_circuit = self._ctx.compile(symbolic_int_sq_circuit)\n",
    "\n",
    "        return circuit, int_sq_circuit\n",
    "    \n",
    "    def _build_region_graph(num_variables:int, depth: int, seed: int = 42) -> RegionGraph:\n",
    "        return RandomBinaryTree(num_variables, depth=depth, seed=seed)\n",
    "\n",
    "    def _build_symbolic_circuit(rg: RegionGraph, *, num_input_units: int, num_sum_units: int) -> Circuit:\n",
    "        def gaussian_layer_factory(\n",
    "            scope: Scope,\n",
    "            num_units: int,\n",
    "            num_channels: int\n",
    "        ) -> GaussianLayer:\n",
    "            return GaussianLayer(\n",
    "                scope, num_units, num_channels,\n",
    "                mean_initializer=NormalInitializer(0.0, 1.0),\n",
    "                stddev_initializer=NormalInitializer(0.0, 1.0),\n",
    "                stddev_parameterization=lambda p: Parameter.from_sequence(\n",
    "                    p, ExpParameter(p.shape), ClampParameter(p.shape, vmin=1e-5)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        def hadamard_layer_factory(\n",
    "            scope: Scope, num_input_units: int, arity: int\n",
    "        ) -> HadamardLayer:\n",
    "            return HadamardLayer(scope, num_input_units, arity)\n",
    "\n",
    "        def dense_layer_factory(\n",
    "            scope: Scope,\n",
    "            num_input_units: int,\n",
    "            num_output_units: int\n",
    "        ) -> DenseLayer:\n",
    "            return DenseLayer(\n",
    "                scope, num_input_units, num_output_units, initializer=UniformInitializer()\n",
    "            )\n",
    "\n",
    "        return Circuit.from_region_graph(\n",
    "            rg,\n",
    "            num_input_units=num_input_units,\n",
    "            num_sum_units=num_sum_units,\n",
    "            input_factory=gaussian_layer_factory,\n",
    "            sum_factory=dense_layer_factory,\n",
    "            prod_factory=hadamard_layer_factory\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf0bd994-1181-4724-acbe-f12bce3d1875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sos = SOS(\n",
    "    num_variables,\n",
    "    num_input_units=32,\n",
    "    num_sum_units=32,\n",
    "    num_squares=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b83e425-d154-474e-af6e-86d34295690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS(\n",
      "  (_circuit): TorchCircuit(\n",
      "    (_nodes): ModuleList(\n",
      "      (0): TorchGaussianLayer(\n",
      "        (mean): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (stddev): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "            (8): TorchExpParameter()\n",
      "            (9): TorchClampParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): TorchHadamardLayer()\n",
      "      (3): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): TorchHadamardLayer()\n",
      "      (5): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): TorchHadamardLayer()\n",
      "      (7): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): TorchHadamardLayer()\n",
      "      (9): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): TorchHadamardLayer()\n",
      "      (11): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): TorchHadamardLayer()\n",
      "      (13): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_int_sq_circuit): TorchConstantCircuit(\n",
      "    (_nodes): ModuleList(\n",
      "      (0): TorchLogPartitionLayer(\n",
      "        (value): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-15): 16 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "            (16): TorchExpParameter()\n",
      "            (17): TorchClampParameter()\n",
      "            (18): TorchGaussianProductLogPartition()\n",
      "            (19-20): 2 x TorchReduceSumParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "            (8): TorchKroneckerParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): TorchHadamardLayer()\n",
      "      (3): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "            (8): TorchKroneckerParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): TorchHadamardLayer()\n",
      "      (5): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "            (8): TorchKroneckerParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): TorchHadamardLayer()\n",
      "      (7): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "            (8): TorchKroneckerParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): TorchHadamardLayer()\n",
      "      (9): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "            (8): TorchKroneckerParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): TorchHadamardLayer()\n",
      "      (11): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "            (8): TorchKroneckerParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): TorchHadamardLayer()\n",
      "      (13): TorchDenseLayer(\n",
      "        (weight): TorchParameter(\n",
      "          (_nodes): ModuleList(\n",
      "            (0-7): 8 x TorchPointerParameter(\n",
      "              (_parameter): TorchTensorParameter()\n",
      "            )\n",
      "            (8): TorchKroneckerParameter()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(sos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6510a-0631-4770-9002-9431f126bb9d",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c644c-ac45-4156-b1f5-391585ea34c7",
   "metadata": {},
   "source": [
    "We are not ready to learn the parameters and do inference.\n",
    "First, we wrap our data into PyTorch data loaders by specifying the batch size.\n",
    "Then, we initialize any PyTorch optimizer, e.g., Adam.\n",
    "\n",
    "Note that the parameters of the integral squared circuit are the same parameters of the circuit itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a0f61c6-7564-4c3b-8612-e02a52160d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea7b248b-802e-4f22-9849-2b5fe304b019",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(data_train, shuffle=True, batch_size=512, drop_last=True, num_workers=4)\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=512, num_workers=4)\n",
    "optimizer = optim.Adam(sos.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee8840b0-617c-4881-8753-313b1491f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move circuit to device\n",
    "sos = sos.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13f65113-023f-4e9f-922a-e7202de5bb43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, step 300: Average NLL: 43.422\n",
      "Epoch 10, step 600: Average NLL: 40.063\n",
      "Epoch 15, step 900: Average NLL: 39.352\n",
      "Epoch 21, step 1200: Average NLL: 38.859\n",
      "Epoch 26, step 1500: Average NLL: 38.471\n",
      "Epoch 31, step 1800: Average NLL: 38.303\n",
      "Epoch 36, step 2100: Average NLL: 38.091\n",
      "Epoch 42, step 2400: Average NLL: 37.988\n",
      "Epoch 47, step 2700: Average NLL: 37.731\n",
      "Epoch 52, step 3000: Average NLL: 37.625\n",
      "Epoch 57, step 3300: Average NLL: 37.355\n",
      "Epoch 63, step 3600: Average NLL: 37.297\n",
      "Epoch 68, step 3900: Average NLL: 37.414\n",
      "Epoch 73, step 4200: Average NLL: 36.903\n",
      "Epoch 78, step 4500: Average NLL: 36.683\n",
      "Epoch 84, step 4800: Average NLL: 36.537\n",
      "Epoch 89, step 5100: Average NLL: 36.289\n",
      "Epoch 94, step 5400: Average NLL: 35.569\n",
      "Epoch 99, step 5700: Average NLL: 36.233\n",
      "Epoch 105, step 6000: Average NLL: 36.981\n",
      "Epoch 110, step 6300: Average NLL: 36.316\n",
      "Epoch 115, step 6600: Average NLL: 36.095\n",
      "Epoch 121, step 6900: Average NLL: 35.573\n",
      "Epoch 126, step 7200: Average NLL: 35.698\n",
      "Epoch 131, step 7500: Average NLL: 35.550\n",
      "Epoch 136, step 7800: Average NLL: 35.879\n",
      "Epoch 142, step 8100: Average NLL: 35.128\n",
      "Epoch 147, step 8400: Average NLL: 34.454\n",
      "Epoch 152, step 8700: Average NLL: 34.226\n",
      "Epoch 157, step 9000: Average NLL: 33.691\n",
      "Epoch 163, step 9300: Average NLL: 34.051\n",
      "Epoch 168, step 9600: Average NLL: 33.345\n",
      "Epoch 173, step 9900: Average NLL: 33.333\n",
      "Epoch 178, step 10200: Average NLL: 32.987\n",
      "Epoch 184, step 10500: Average NLL: 32.838\n",
      "Epoch 189, step 10800: Average NLL: 32.668\n",
      "Epoch 194, step 11100: Average NLL: 32.492\n",
      "Epoch 199, step 11400: Average NLL: 32.320\n",
      "Epoch 205, step 11700: Average NLL: 32.196\n",
      "Epoch 210, step 12000: Average NLL: 31.604\n",
      "Epoch 215, step 12300: Average NLL: 31.225\n",
      "Epoch 221, step 12600: Average NLL: 30.851\n",
      "Epoch 226, step 12900: Average NLL: 30.718\n",
      "Epoch 231, step 13200: Average NLL: 30.976\n",
      "Epoch 236, step 13500: Average NLL: 30.910\n",
      "Epoch 242, step 13800: Average NLL: 31.258\n",
      "Epoch 247, step 14100: Average NLL: 30.803\n",
      "Epoch 252, step 14400: Average NLL: 31.005\n",
      "Epoch 257, step 14700: Average NLL: 31.154\n",
      "Epoch 263, step 15000: Average NLL: 30.662\n",
      "Epoch 268, step 15300: Average NLL: 30.593\n",
      "Epoch 273, step 15600: Average NLL: 31.336\n",
      "Epoch 278, step 15900: Average NLL: 31.645\n",
      "Epoch 284, step 16200: Average NLL: 31.185\n",
      "Epoch 289, step 16500: Average NLL: 30.778\n",
      "Epoch 294, step 16800: Average NLL: 30.243\n",
      "Epoch 299, step 17100: Average NLL: 29.887\n",
      "Epoch 305, step 17400: Average NLL: 29.673\n",
      "Epoch 310, step 17700: Average NLL: 29.495\n",
      "Epoch 315, step 18000: Average NLL: 29.190\n",
      "Epoch 321, step 18300: Average NLL: 29.080\n",
      "Epoch 326, step 18600: Average NLL: 28.994\n",
      "Epoch 331, step 18900: Average NLL: 28.754\n",
      "Epoch 336, step 19200: Average NLL: 28.742\n",
      "Epoch 342, step 19500: Average NLL: 28.713\n",
      "Epoch 347, step 19800: Average NLL: 28.555\n",
      "Epoch 352, step 20100: Average NLL: 28.377\n",
      "Epoch 357, step 20400: Average NLL: 28.547\n",
      "Epoch 363, step 20700: Average NLL: 28.793\n",
      "Epoch 368, step 21000: Average NLL: 28.818\n",
      "Epoch 373, step 21300: Average NLL: 28.674\n",
      "Epoch 378, step 21600: Average NLL: 28.943\n",
      "Epoch 384, step 21900: Average NLL: 28.926\n",
      "Epoch 389, step 22200: Average NLL: 28.635\n",
      "Epoch 394, step 22500: Average NLL: 28.535\n",
      "Epoch 399, step 22800: Average NLL: 28.466\n",
      "Epoch 405, step 23100: Average NLL: 28.076\n",
      "Epoch 410, step 23400: Average NLL: 28.082\n",
      "Epoch 415, step 23700: Average NLL: 27.784\n",
      "Epoch 421, step 24000: Average NLL: 27.625\n",
      "Epoch 426, step 24300: Average NLL: 27.605\n",
      "Epoch 431, step 24600: Average NLL: 27.502\n",
      "Epoch 436, step 24900: Average NLL: 27.600\n",
      "Epoch 442, step 25200: Average NLL: 27.519\n",
      "Epoch 447, step 25500: Average NLL: 27.322\n",
      "Epoch 452, step 25800: Average NLL: 27.201\n",
      "Epoch 457, step 26100: Average NLL: 27.130\n",
      "Epoch 463, step 26400: Average NLL: 27.390\n",
      "Epoch 468, step 26700: Average NLL: 27.248\n",
      "Epoch 473, step 27000: Average NLL: 26.945\n",
      "Epoch 478, step 27300: Average NLL: 26.895\n",
      "Epoch 484, step 27600: Average NLL: 26.797\n",
      "Epoch 489, step 27900: Average NLL: 26.642\n",
      "Epoch 494, step 28200: Average NLL: 26.575\n",
      "Epoch 499, step 28500: Average NLL: 27.023\n"
     ]
    }
   ],
   "source": [
    "sos.train()\n",
    "num_epochs = 500\n",
    "step_idx = 0\n",
    "running_loss = 0.0\n",
    "for epoch_idx in range(num_epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        batch = batch.to(device).unsqueeze(dim=1)   # Add a channel dimension\n",
    "        lls = sos.log_likelihood(batch)             # Compute the log-likelihood\n",
    "        loss = -torch.mean(lls)   # The loss is the negative average log-likelihood\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.detach() * len(batch)\n",
    "        step_idx += 1\n",
    "        if step_idx % 300 == 0:\n",
    "            print(f\"Epoch {epoch_idx}, step {step_idx}: Average NLL: {running_loss / (300 * len(batch)):.3f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b712e5df-4ad2-4ae1-a7e3-f0c1df7db254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test LL: -28.711\n"
     ]
    }
   ],
   "source": [
    "sos.eval()\n",
    "with torch.no_grad():\n",
    "    test_lls = 0.0\n",
    "    for batch in test_dataloader:\n",
    "        batch = batch.to(device).unsqueeze(dim=1)   # Add a channel dimension\n",
    "        lls = sos.log_likelihood(batch)             # Compute the log-likelihood\n",
    "        test_lls += lls.sum().item()\n",
    "    average_ll = test_lls / len(data_test)\n",
    "    print(f\"Average test LL: {average_ll:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83af093-ce24-464c-bf0b-abee49d58e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
