{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e6d6b9",
   "metadata": {},
   "source": [
    "# Train and evaluate a PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6debe19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:00.389824Z",
     "start_time": "2024-07-29T10:05:00.082764Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4608165",
   "metadata": {},
   "source": [
    "Set the random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66933b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:00.393664Z",
     "start_time": "2024-07-29T10:05:00.391228Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c005fb",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02baea",
   "metadata": {},
   "source": [
    "Load the training and test splits of MNIST, and preprocess them by flattening the tensor images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a04559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:01.606682Z",
     "start_time": "2024-07-29T10:05:00.394374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables: 784\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (255 * x.view(-1)).long())\n",
    "])\n",
    "data_train = datasets.MNIST('datasets', train=True, download=True, transform=transform)\n",
    "data_test = datasets.MNIST('datasets', train=False, download=True, transform=transform)\n",
    "num_variables = data_train[0][0].shape[0]\n",
    "height, width = 28, 28\n",
    "print(f\"Number of variables: {num_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad24d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:01.776666Z",
     "start_time": "2024-07-29T10:05:01.607634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(data_train[0][0].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Class: {data_train[0][1]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965d0122",
   "metadata": {},
   "source": [
    "## Instantiating a Circuit structure Template: the Region Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d471b6e",
   "metadata": {},
   "source": [
    "Initialize a _Quad Graph_ region graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a7b261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:01.919648Z",
     "start_time": "2024-07-29T10:05:01.777546Z"
    }
   },
   "outputs": [],
   "source": [
    "from cirkit.templates.region_graph import QuadTree\n",
    "region_graph = QuadTree(shape=(height, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc35ef6",
   "metadata": {},
   "source": [
    "Others available region graphs are the _Random Binary Tree_ and the _Poon Domingos_, whose imports are showed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec3a1ea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:01.923027Z",
     "start_time": "2024-07-29T10:05:01.921033Z"
    }
   },
   "outputs": [],
   "source": [
    "from cirkit.templates.region_graph import RandomBinaryTree, PoonDomingos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66900897-5d65-4136-8399-f997c3665a38",
   "metadata": {},
   "source": [
    "## Constructing the Symbolic Circuit Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6468f6-a1e5-46f8-92d4-d1eb6fa5ba19",
   "metadata": {},
   "source": [
    "From the region graph definition above, we now construct the symbolic circuit representation. Note that this circuit representation is _not_ executable, i.e., you cannot do learn it or do inference with it. It will be compiled later, by choosing a backend such as torch.\n",
    "\n",
    "To do so, we first define the factories that will be used to construct symbolic layers. Note that we choose the parameterization at the symbolic level. That is, we guarantee non-negative parameters by passing them through an exponential function. Moreover, we can choose how to parameterize the categorical distributions used to model the distribution of pixel values in the 0-255 range. In this case, we use a log softmax function. We choose to initialize the weights of the circuit by sampling from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac0a1895-999f-47af-8c6f-57242726540a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:01.942566Z",
     "start_time": "2024-07-29T10:05:01.923623Z"
    }
   },
   "outputs": [],
   "source": [
    "from cirkit.utils.scope import Scope\n",
    "from cirkit.symbolic.parameters import LogSoftmaxParameter, SoftmaxParameter, ExpParameter, Parameter, TensorParameter\n",
    "from cirkit.symbolic.layers import CategoricalLayer, DenseLayer, HadamardLayer, MixingLayer\n",
    "from cirkit.symbolic.initializers import NormalInitializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96b9dfc-83a6-43ba-b20d-48d6dd79e663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:01.949067Z",
     "start_time": "2024-07-29T10:05:01.943376Z"
    }
   },
   "outputs": [],
   "source": [
    "def categorical_layer_factory(\n",
    "    scope: Scope,\n",
    "    num_units: int,\n",
    "    num_channels: int\n",
    ") -> CategoricalLayer:\n",
    "    return CategoricalLayer(\n",
    "        scope, num_units, num_channels, num_categories=256,\n",
    "        logits_factory=lambda shape: Parameter.from_unary(\n",
    "            LogSoftmaxParameter(shape),\n",
    "            TensorParameter(*shape, initializer=NormalInitializer(0.0, 1e-2))\n",
    "        )\n",
    "    )\n",
    "\n",
    "def hadamard_layer_factory(\n",
    "    scope: Scope, num_input_units: int, arity: int\n",
    ") -> HadamardLayer:\n",
    "    return HadamardLayer(scope, num_input_units, arity)\n",
    "\n",
    "def dense_layer_factory(\n",
    "    scope: Scope,\n",
    "    num_input_units: int,\n",
    "    num_output_units: int\n",
    ") -> DenseLayer:\n",
    "    return DenseLayer(\n",
    "        scope, num_input_units, num_output_units,\n",
    "        weight_factory=lambda shape: Parameter.from_unary(\n",
    "            SoftmaxParameter(shape),\n",
    "            TensorParameter(*shape, initializer=NormalInitializer(0.0, 1e-1))\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def mixing_layer_factory(\n",
    "    scope: Scope, num_units: int, arity: int\n",
    ") -> MixingLayer:\n",
    "    return MixingLayer(\n",
    "        scope, num_units, arity,\n",
    "        weight_factory=lambda shape: Parameter.from_unary(\n",
    "            SoftmaxParameter(shape),\n",
    "            TensorParameter(*shape, initializer=NormalInitializer(0.0, 1e-1))\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9707de19-d6c7-4646-8266-2e20dcefa22e",
   "metadata": {},
   "source": [
    "Then, we call a function to construct the symbolic circuit from region graph, by specifying the number of units and the factories to build layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97be2b8f-0012-46ed-9f03-26a7a4729b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:01.963116Z",
     "start_time": "2024-07-29T10:05:01.949714Z"
    }
   },
   "outputs": [],
   "source": [
    "from cirkit.symbolic.circuit import Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c88f38-1552-4d13-b62d-931493c07c69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:02.006507Z",
     "start_time": "2024-07-29T10:05:01.963745Z"
    }
   },
   "outputs": [],
   "source": [
    "symbolic_circuit = Circuit.from_region_graph(\n",
    "    region_graph,\n",
    "    num_input_units=8,\n",
    "    num_sum_units=8,\n",
    "    input_factory=categorical_layer_factory,\n",
    "    sum_factory=dense_layer_factory,\n",
    "    prod_factory=hadamard_layer_factory,\n",
    "    mixing_factory=mixing_layer_factory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c6e7c-ad9f-4dd2-ab76-602e191d197b",
   "metadata": {},
   "source": [
    "We can retrieve some information about the circuit and its structural properties as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23570bfd-a64e-4e19-ba4c-30e489e9d08d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:02.020893Z",
     "start_time": "2024-07-29T10:05:02.007312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smooth: True\n",
      "Decomposable: True\n",
      "Number of variables: 784\n",
      "Number of channels per variable: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Smooth: {symbolic_circuit.is_smooth}')\n",
    "print(f'Decomposable: {symbolic_circuit.is_decomposable}')\n",
    "print(f'Number of variables: {symbolic_circuit.num_variables}')\n",
    "print(f'Number of channels per variable: {symbolic_circuit.num_channels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67398c38",
   "metadata": {},
   "source": [
    "## Compiling the Symbolic Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba547d8",
   "metadata": {},
   "source": [
    "We are ready to compile the symbolic circuit constructed above into another one that we can learn and/or do inference. To do so, we have to choose a compilation backend. In this case, we choose torch as a backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ea4a4a-649d-462f-bcfd-20a12bd8a052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:02.031099Z",
     "start_time": "2024-07-29T10:05:02.021697Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')  # The device to use\n",
    "torch.manual_seed(42)\n",
    "if 'cuda' in device.type:\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f7a3f9-1c64-4117-81f0-8766ccbd3179",
   "metadata": {},
   "source": [
    "We first need to instantiate a circuit pipeline context and specify the backend to be used, as well as optional compilation flags, e.g., whether to fold the circuit or which inference semiring to use. Finally, we use the pipeline context to compile the symbolic circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af58c11e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:02.050906Z",
     "start_time": "2024-07-29T10:05:02.031666Z"
    }
   },
   "outputs": [],
   "source": [
    "from cirkit.pipeline import PipelineContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a1892e-4a65-4759-bb3a-ccbe6f5e515c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:02.708666Z",
     "start_time": "2024-07-29T10:05:02.051650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 646 ms, sys: 22.2 ms, total: 668 ms\n",
      "Wall time: 667 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ctx = PipelineContext(\n",
    "    backend='torch',   # Choose the torch compilation backend\n",
    "    fold=True,         # Fold the circuit, this is a backend-specific compilation flag\n",
    "    semiring='lse-sum' # Use the (R, +, *) semiring, where + is the log-sum-exp and * is the sum\n",
    ")\n",
    "circuit = ctx.compile(symbolic_circuit)\n",
    "\n",
    "# Alternatively, one can use the Python _with_ statement to compile circuits inside of it.\n",
    "#\n",
    "# from cirkit.pipeline import compile\n",
    "# with PipelineContext(backend='torch', fold=True, semiring='lse-sum') as ctx:\n",
    "#    circuit = compile(symbolic_circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd14baf-a29e-4773-84a7-417d8747f678",
   "metadata": {},
   "source": [
    "Note that the compilation step, comprising the folding optimization, required less than 1 second for a circuit with almost 5000 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36f0d55e-05c3-42ac-a63c-326f8446f90d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:02.712918Z",
     "start_time": "2024-07-29T10:05:02.710290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4947\n"
     ]
    }
   ],
   "source": [
    "print(len(list(symbolic_circuit.layers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce78e8-79fc-4630-8cea-ce6e0df4429b",
   "metadata": {},
   "source": [
    "We observe how the tensorized circuit has much fewer layers, as the great majority has been folded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc7965af-05d3-472f-84cb-7c3d80da52fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:02.722401Z",
     "start_time": "2024-07-29T10:05:02.713634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchCircuit(\n",
      "  (_nodes): ModuleList(\n",
      "    (0): TorchCategoricalLayer(\n",
      "      (logits): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchLogSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): TorchHadamardLayer()\n",
      "    (3): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): TorchHadamardLayer()\n",
      "    (5): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): TorchMixingLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): TorchHadamardLayer()\n",
      "    (8): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): TorchHadamardLayer()\n",
      "    (10): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): TorchMixingLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): TorchHadamardLayer()\n",
      "    (13): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): TorchHadamardLayer()\n",
      "    (15): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): TorchMixingLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): TorchHadamardLayer()\n",
      "    (18): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): TorchHadamardLayer()\n",
      "    (20): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (21): TorchMixingLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): TorchHadamardLayer()\n",
      "    (23): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (24): TorchHadamardLayer()\n",
      "    (25): TorchDenseLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (26): TorchMixingLayer(\n",
      "      (weight): TorchParameter(\n",
      "        (_nodes): ModuleList(\n",
      "          (0): TorchTensorParameter()\n",
      "          (1): TorchSoftmaxParameter()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beee1f04",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf4858",
   "metadata": {},
   "source": [
    "We are now ready to learn the parameters and do inference First, we wrap our data into PyTorch data loaders by specifying the batch size. Then, we initialize any PyTorch optimizer, e.g. SGD with momentum in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02854883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:02.738365Z",
     "start_time": "2024-07-29T10:05:02.723726Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(data_train, shuffle=True, batch_size=256, drop_last=True, num_workers=4)\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=256, num_workers=4)\n",
    "optimizer = optim.SGD(circuit.parameters(), lr=0.1, momentum=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab362742-03af-4839-a302-44c8492a370e",
   "metadata": {},
   "source": [
    "### Compiling the Circuit computing the Partition Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac573d",
   "metadata": {},
   "source": [
    "Here, we choose to optimize the parameters by minimizing the negative log-likelihood. However, since the circuit is not already normalized (as we parameterized the sums using an exponential), we need to instantiate a circuit computing the partition function explicitly. That is, we integrate the circuit within the pipeline context as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de1ae885-d02a-4c94-829e-dc491a8c4a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:03.969525Z",
     "start_time": "2024-07-29T10:05:02.740698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cirkit.backend.torch.circuits.TorchConstantCircuit'>\n"
     ]
    }
   ],
   "source": [
    "pf_circuit = ctx.integrate(circuit)\n",
    "\n",
    "# Alternatively, one can use the _with_ statement.\n",
    "#\n",
    "# from cirkit.pipeline import integrate\n",
    "# with ctx:\n",
    "#     pf_circuit = integrate(tensorized_circuit)\n",
    "\n",
    "# Another way to perform the integration is by using the _symbolic functional_ APIs.\n",
    "# This gives us additional flexibility by operating over circuits _before compiling them_.\n",
    "#\n",
    "# import cirkit.symbolic.functional as SF\n",
    "# with ctx:\n",
    "#     pf_symbolic_circuit = SF.integrate(symbolic_circuit)\n",
    "#     pf_circuit = compile(pf_symbolic_circuit)\n",
    "\n",
    "# The type of the circuit obtained by integration of all variables is a 'constant' circuit,\n",
    "# i.e., it does not take inputs.\n",
    "print(type(pf_circuit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05e268-4ab0-4c65-94b6-f624329bee55",
   "metadata": {},
   "source": [
    "Note that the context will take care of the parameters being shared between the compiled circuit and its other version, which computes the partition function. Finally, we learn the parameters by minimizing the negative log-likelihood, similarly as any other model in torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eb6683d-f7c0-4b70-afd1-912a90861c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:05:04.057160Z",
     "start_time": "2024-07-29T10:05:03.970284Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Move circuits to device\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m circuit \u001b[38;5;241m=\u001b[39m \u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m pf_circuit \u001b[38;5;241m=\u001b[39m pf_circuit\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Documents/cirkit/cirkit/backend/torch/graph/modules.py:68\u001b[0m, in \u001b[0;36mTorchDiAcyclicGraph.to\u001b[0;34m(self, device, dtype, non_blocking)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     63\u001b[0m     device: Optional[Union[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     64\u001b[0m     dtype: Optional[torch\u001b[38;5;241m.\u001b[39mdtype] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     65\u001b[0m     non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     66\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorchDiAcyclicGraph\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_address_book\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(TorchDiAcyclicGraph, \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(device, dtype, non_blocking))\n",
      "File \u001b[0;32m~/Documents/cirkit/cirkit/backend/torch/graph/address_book.py:31\u001b[0m, in \u001b[0;36mAddressBook.set_device\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Optional[Union[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddressBook\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAddressBookEntry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_module_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_fold_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_entries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/cirkit/cirkit/backend/torch/graph/address_book.py:35\u001b[0m, in \u001b[0;36mAddressBook.set_device.<locals>.<lambda>\u001b[0;34m(entry)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Optional[Union[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddressBook\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m entry: AddressBookEntry(\n\u001b[1;32m     34\u001b[0m                 entry\u001b[38;5;241m.\u001b[39min_module_ids,\n\u001b[0;32m---> 35\u001b[0m                 [idx \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m entry\u001b[38;5;241m.\u001b[39min_fold_idx],\n\u001b[1;32m     36\u001b[0m             ),\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entries,\n\u001b[1;32m     38\u001b[0m         )\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/cirkit/cirkit/backend/torch/graph/address_book.py:35\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Optional[Union[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddressBook\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m entry: AddressBookEntry(\n\u001b[1;32m     34\u001b[0m                 entry\u001b[38;5;241m.\u001b[39min_module_ids,\n\u001b[0;32m---> 35\u001b[0m                 [idx \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43midx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m entry\u001b[38;5;241m.\u001b[39min_fold_idx],\n\u001b[1;32m     36\u001b[0m             ),\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entries,\n\u001b[1;32m     38\u001b[0m         )\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/cirkit/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:314\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    313\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 314\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    318\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Move circuits to device\n",
    "circuit = circuit.to(device)\n",
    "pf_circuit = pf_circuit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28e9c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:09:15.068392Z",
     "start_time": "2024-07-29T10:05:04.057950Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "step_idx = 0\n",
    "running_loss = 0.0\n",
    "for epoch_idx in range(num_epochs):\n",
    "    for i, (batch, _) in enumerate(train_dataloader):\n",
    "        batch = batch.to(device).unsqueeze(dim=1)   # Add a channel dimension\n",
    "        log_output = circuit(batch)                 # Compute the log output of the circuit\n",
    "        log_pf = pf_circuit()                       # Compute the log partition function of the circuit\n",
    "        lls = log_output - log_pf                   # Compute the log-likelihood\n",
    "        loss = -torch.mean(lls)   # The loss is the negative average log-likelihood\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.detach() * len(batch)\n",
    "        step_idx += 1\n",
    "        if step_idx % 100 == 0:\n",
    "            print(f\"Step {step_idx}: Average NLL: {running_loss / (100 * len(batch)):.3f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efae6b",
   "metadata": {},
   "source": [
    "We then evaluate our model on test data by computing the average log-likelihood and bits per dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc335f725d9f18d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:09:16.029751Z",
     "start_time": "2024-07-29T10:09:15.069468Z"
    }
   },
   "outputs": [],
   "source": [
    "circuit.eval()\n",
    "pf_circuit.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_lls = 0.0\n",
    "    log_pf = pf_circuit()  # Compute the log partition function of the circuit (just once as we are evaluating)\n",
    "    for batch, _ in test_dataloader:\n",
    "        batch = batch.to(device).unsqueeze(dim=1)   # Add a channel dimension\n",
    "        log_output = circuit(batch)                 # Compute the log output of the circuit\n",
    "        lls = log_output - log_pf                   # Compute the log-likelihood\n",
    "        test_lls += lls.sum().item()\n",
    "    average_ll = test_lls / len(data_test)\n",
    "    bpd = -average_ll / (num_variables * np.log(2.0))\n",
    "    print(f\"Average test LL: {average_ll:.3f}\")\n",
    "    print(f\"Bits per dimension: {bpd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b11214b2c17f2e0",
   "metadata": {},
   "source": [
    "## Forward Sampling from the Circuit\n",
    "\n",
    "To visualise the generative capabilities of the circuit, we can sample from it by performing forward sampling and plot the results. Note that the sampling operation returns samples from the leaves *and* samples from the corresponding mixtures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2244ab3fc34ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:09:16.227702Z",
     "start_time": "2024-07-29T10:09:16.030589Z"
    }
   },
   "outputs": [],
   "source": [
    "import einops as E\n",
    "\n",
    "samples = circuit.sample_forward(5)\n",
    "leaf_samples = samples[0]\n",
    "mixtures_samples = samples[1]\n",
    "\n",
    "leaf_samples = leaf_samples[:, 0, :] # Remove the channel dimension\n",
    "samples = E.rearrange(leaf_samples, \"n (h w) -> n h w\", h=28, w=28)\n",
    "samples = samples.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(5, 1))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(samples[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe769dfc7de41a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:09:16.418453Z",
     "start_time": "2024-07-29T10:09:16.228958Z"
    }
   },
   "outputs": [],
   "source": [
    "import einops as E\n",
    "\n",
    "samples = circuit.sample_forward(10)\n",
    "\n",
    "leaf_samples = samples[0]\n",
    "mixture_samples = samples[1]\n",
    "\n",
    "generations = E.rearrange(leaf_samples[:, 0, :], \"n (h w) -> n h w\", h=28, w=28)\n",
    "generations = generations.cpu().numpy()\n",
    "\n",
    "# plot here now\n",
    "plt.figure(figsize=(5, 1))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(generations[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a1be60248cfd8",
   "metadata": {},
   "source": [
    "For future use, you can also evaluate the \"extended\" log likelihood of the circuit, which includes the log likelihood of the mixture components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ddba06bd6870ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:09:16.436809Z",
     "start_time": "2024-07-29T10:09:16.419558Z"
    }
   },
   "outputs": [],
   "source": [
    "log_p = circuit(leaf_samples)\n",
    "joint_log_p = circuit.extended_forward(leaf_samples, mixture_samples)\n",
    "\n",
    "print(f\"Log probability: {log_p.shape}\")\n",
    "print(f\"Joint log probability: {joint_log_p.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
